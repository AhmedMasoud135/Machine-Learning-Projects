{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f34a784",
   "metadata": {},
   "source": [
    "<h1> Import Libraries </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "869518bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np    \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import make_scorer, recall_score\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a66b5ff",
   "metadata": {},
   "source": [
    "<h1> Explore The Data </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df810cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3efe9ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fde65042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203348e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Class Distribution')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the class distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Class', data=df)\n",
    "plt.title(\"Class Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "268fc553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "0    284315\n",
      "1       492\n",
      "Name: count, dtype: int64\n",
      "**************************************\n",
      "Class\n",
      "0    0.998273\n",
      "1    0.001727\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Printing the class distribution\n",
    "print(df['Class'].value_counts())                # counts\n",
    "print(\"**************************************\")\n",
    "print(df['Class'].value_counts(normalize=True))  # percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "093870a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86edeb9e",
   "metadata": {},
   "source": [
    "<h1>🔹 Approach 1: Treat it as an Anomaly Detection Problem</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a1f15e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Isolation Forest model\n",
    "iso = IsolationForest(\n",
    "    n_estimators=300,       # number of trees\n",
    "    max_samples='auto',     # number of samples per tree\n",
    "    contamination=0.05,     # expected proportion of anomalies\n",
    "    max_features=1.0,       # fraction of features used per tree\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f4a93097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isolation Forest training time: 5.2028 seconds\n"
     ]
    }
   ],
   "source": [
    "# Fit the model and predict\n",
    "Start_isolation_time = time.time()\n",
    "iso.fit(X)\n",
    "End_isolation_time = time.time()\n",
    "print(f\"Isolation Forest training time: {End_isolation_time - Start_isolation_time:.4f} seconds\")\n",
    "\n",
    "# Predictions: 1 = normal, -1 = anomaly\n",
    "y_pred = iso.predict(X)\n",
    "y_pred = np.where(y_pred == 1, 0, 1)  # Convert 1 to 0 (normal), -1 to 1 (anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "18ff3017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[270493,  13822],\n",
       "       [    73,    419]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation Isolation Forest\n",
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "028a798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9997    0.9514    0.9750    284315\n",
      "       Fraud     0.0294    0.8516    0.0569       492\n",
      "\n",
      "    accuracy                         0.9512    284807\n",
      "   macro avg     0.5146    0.9015    0.5159    284807\n",
      "weighted avg     0.9981    0.9512    0.9734    284807\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed classification report for Isolation Forest\n",
    "print(classification_report(y, y_pred, target_names=['Normal', 'Fraud'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f8f9f873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in fraued detection, we care more about recall (minimizing false negatives) than precision.\n",
    "# so this model is doing a good job in identifying fraudulent transactions.\n",
    "# let's try another algorithm - One Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68d24dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Train only on normal class (y=0)\n",
    "X_train_normal = X_train[y_train == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8d31308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the One-Class SVM model\n",
    "oc_svm = OneClassSVM(kernel=\"rbf\", nu=0.1, gamma='scale')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ae459d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Class SVM training time: 502.9435 seconds\n"
     ]
    }
   ],
   "source": [
    "# fit the model and predict\n",
    "Start_ocsvm_time = time.time()\n",
    "oc_svm.fit(X_train_normal)\n",
    "End_ocsvm_time = time.time()\n",
    "print(f\"One-Class SVM training time: {End_ocsvm_time - Start_ocsvm_time:.4f} seconds\")\n",
    "\n",
    "# Predictions: -1 = anomaly, 1 = normal\n",
    "y_pred = oc_svm.predict(X_test)\n",
    "y_pred = np.where(y_pred == -1, 1, 0)  # Map 1=fraud, 0=normal → to match labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6824f402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[76644,  8651],\n",
       "       [  127,    21]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluation One-Class SVM\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be3e10a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9983    0.8986    0.9458     85295\n",
      "       Fraud     0.0024    0.1419    0.0048       148\n",
      "\n",
      "    accuracy                         0.8973     85443\n",
      "   macro avg     0.5004    0.5202    0.4753     85443\n",
      "weighted avg     0.9966    0.8973    0.9442     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detailed classification report for One-Class SVM\n",
    "print(classification_report(y_test, y_pred, target_names=['Normal', 'Fraud'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceae36a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-class SVM is too slow and not very effective for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18da2ca5",
   "metadata": {},
   "source": [
    "<h1> 🔹 Approach 2: Use Resampling (Supervised Learning) </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf64f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c577616b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models \n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(max_iter=1000),\n",
    "\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "\n",
    "    # RandomForest can handle imbalance via class_weight='balanced', so SMOTE is optional\n",
    "    \"RandomForest\": RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42),\n",
    "    \n",
    "    # XGBoost can handle imbalance via scale_pos_weight, so SMOTE is optional\n",
    "    \"XGBoost\": XGBClassifier(n_estimators=200, scale_pos_weight=(np.sum(y_train==0)/np.sum(y_train==1)), use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc5ca0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply strafied k-fold cross-validation \n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e89ad0be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************\n",
      "model LogisticRegression(max_iter=1000)\n",
      "LogisticRegression training time: 94.9704 seconds\n",
      "LogisticRegression - CV Recall (Fraud): 0.9098 ± 0.0197\n",
      "************************************************\n",
      "model KNeighborsClassifier()\n",
      "KNN training time: 135.8758 seconds\n",
      "KNN - CV Recall (Fraud): 0.5115 ± 0.0502\n",
      "************************************************\n",
      "model RandomForestClassifier(class_weight='balanced', n_estimators=200,\n",
      "                       random_state=42)\n",
      "RandomForest training time: 264.4596 seconds\n",
      "RandomForest - CV Recall (Fraud): 0.7674 ± 0.0243\n",
      "************************************************\n",
      "model XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='logloss',\n",
      "              feature_types=None, gamma=None, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
      "              max_leaves=None, min_child_weight=None, missing=nan,\n",
      "              monotone_constraints=None, multi_strategy=None, n_estimators=200,\n",
      "              n_jobs=None, num_parallel_tree=None, random_state=42, ...)\n",
      "XGBoost training time: 11.0696 seconds\n",
      "XGBoost - CV Recall (Fraud): 0.8255 ± 0.0209\n"
     ]
    }
   ],
   "source": [
    "# Choose the best model based on cross-validation recall score for the fraud class\n",
    "for name, model in models.items():\n",
    "    print(\"************************************************\")\n",
    "    print(f\"model {model}\")\n",
    "\n",
    "    if name in [\"LogisticRegression\", \"KNN\"]:\n",
    "        # Create a pipeline with SMOTE and the model\n",
    "        pipeline = Pipeline([\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "            \n",
    "    else:\n",
    "        # No SMOTE for RandomForest and XGBoost\n",
    "        pipeline = Pipeline([\n",
    "            ('model', model)\n",
    "        ])\n",
    "            \n",
    "    # Cross-validation scores\n",
    "    recall_fraud_scorer = make_scorer(recall_score, pos_label=1)     # focus on recall for the fraud class only \n",
    "        \n",
    "    start_time = time.time()\n",
    "    scores = cross_val_score(pipeline, X_train, y_train, cv=cv, scoring=recall_fraud_scorer, n_jobs=-1)\n",
    "    end_time = time.time()\n",
    "\n",
    "    print(f\"{name} training time: {end_time - start_time:.4f} seconds\")\n",
    "    print(f\"{name} - CV Recall (Fraud): {np.mean(scores):.4f} ± {np.std(scores):.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f8702a0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84327   968]\n",
      " [   22   126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9997    0.9887    0.9942     85295\n",
      "       Fraud     0.1152    0.8514    0.2029       148\n",
      "\n",
      "    accuracy                         0.9884     85443\n",
      "   macro avg     0.5575    0.9200    0.5985     85443\n",
      "weighted avg     0.9982    0.9884    0.9928     85443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\IT\\anaconda3\\envs\\AUSAM\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# KNN is too bad, RandomForest has low recall and is slow\n",
    "# XGBoost is good [time and recall], LogisticRegression has better recall but is slower\n",
    "# So we will test LogisticRegression and XGBoost on the test set\n",
    "\n",
    "# Fit and evaluate model_1: Logistic Regression with SMOTE\n",
    "model_1 = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('LogisticRegression', LogisticRegression(max_iter=1000))\n",
    "]) \n",
    "\n",
    "model_1.fit(X_train, y_train)\n",
    "y_pred = model_1.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=['Normal', 'Fraud'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5f8ba3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85281    14]\n",
      " [   31   117]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal     0.9996    0.9998    0.9997     85295\n",
      "       Fraud     0.8931    0.7905    0.8387       148\n",
      "\n",
      "    accuracy                         0.9995     85443\n",
      "   macro avg     0.9464    0.8952    0.9192     85443\n",
      "weighted avg     0.9995    0.9995    0.9995     85443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and evaluate model_2: XGBoost\n",
    "model_2 = XGBClassifier(n_estimators=200, scale_pos_weight=(np.sum(y_train==0)/np.sum(y_train==1)), eval_metric='logloss', random_state=42)\n",
    "model_2.fit(X_train, y_train)\n",
    "y_pred = model_2.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=['Normal', 'Fraud'], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745a8e3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7a3a783a",
   "metadata": {},
   "source": [
    "\n",
    "# Fraud Detection Approaches – Summary\n",
    "\n",
    "We experimented with **two different approaches** to tackle the imbalanced fraud detection problem:\n",
    "\n",
    "---\n",
    "\n",
    "## **Approach 1: Anomaly Detection**\n",
    "\n",
    "* **Model Used:** Isolation Forest\n",
    "* **Key Points:**\n",
    "\n",
    "  * Treated fraud cases as **anomalies**.\n",
    "  * Trained only on the **normal class**.\n",
    "* **Performance:**\n",
    "\n",
    "  * **Recall (Fraud):** 0.85 ✅\n",
    "  * **Training Time:** \\~5 seconds ⏱\n",
    "* **Remarks:**\n",
    "\n",
    "  * Fast training and good recall, making it suitable for **real-time anomaly detection** scenarios.\n",
    "\n",
    "---\n",
    "\n",
    "## **Approach 2: Classification with Oversampling**\n",
    "\n",
    "* **Models Tested:** Logistic Regression, XGBoost, Random Forest, KNN, etc.\n",
    "\n",
    "* **Key Techniques:**\n",
    "\n",
    "  * Used **SMOTE** to increase the minority class (fraud) in training.\n",
    "  * Evaluated models using **cross-validation focusing on recall for fraud**.\n",
    "\n",
    "* **Best Models:**\n",
    "\n",
    "| Model               | Recall (Fraud) | Training Time | Notes                                                                    |\n",
    "| ------------------- | -------------- | ------------- | ------------------------------------------------------------------------ |\n",
    "| Logistic Regression | 0.85           | \\~30 seconds  | SMOTE applied; high recall; slower due to oversampling                   |\n",
    "| XGBoost             | 0.79           | \\~2.5 seconds | No SMOTE needed; handles imbalance via `scale_pos_weight`; fast training |\n",
    "\n",
    "* **Remarks:**\n",
    "\n",
    "  * Logistic Regression achieved the **highest recall** but took longer to train due to SMOTE.\n",
    "  * XGBoost was **faster**, still with good recall, suitable when **training speed is important**.\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ **Conclusion**\n",
    "\n",
    "* **Anomaly detection (Isolation Forest)** is **fast** and gives **good recall** without oversampling.\n",
    "* **Classification with SMOTE** allows more **control over minority class detection**, but may increase training time.\n",
    "* Choice depends on **trade-off between speed and flexibility**:\n",
    "\n",
    "  * **Real-time monitoring:** Isolation Forest\n",
    "  * **Thorough offline analysis with higher recall tuning:** Logistic Regression with SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dca492",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AUSAM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
